# Clasificaci√≥n de Rese√±as con Naive Bayes  

‚ö†Ô∏è Proyecto en construcci√≥n. Pr√≥ximamente se agregar√°n comparaciones con otros modelos de NLP.  

## üìå Objetivo  
Explorar un m√©todo cl√°sico de Machine Learning (Naive Bayes) para clasificar rese√±as de productos en positivas o negativas.  

## üß© Contenido  
- Limpieza y preprocesamiento de texto  
- Representaci√≥n con Bag-of-Words / TF-IDF  
- Entrenamiento del modelo Naive Bayes  
- Evaluaci√≥n de m√©tricas (accuracy, precision, recall, f1-score)  
- Ejemplos pr√°cticos de clasificaci√≥n de nuevas rese√±as  

## üìä Resultados principales  

| Clase         | Precision | Recall | F1-score | Soporte |
|---------------|-----------|--------|----------|---------|
| Negativa (0)  | 0.83      | 0.81   | 0.82     | 25,138  |
| Positiva (1)  | 0.73      | 0.75   | 0.74     | 16,862  |
| **Accuracy**  |           |        | **0.785**| 42,000  |
| **Macro avg** | 0.78      | 0.78   | 0.78     | 42,000  |
| **Weighted avg** | 0.79   | 0.79   | 0.79     | 42,000  |

## ‚úÖ Conclusi√≥n  
- El modelo alcanz√≥ un **accuracy del 78,5%**.  
- La clase negativa mantiene un alto nivel de desempe√±o (f1-score 0.82).  
- La clase positiva tambi√©n logra m√©tricas consistentes (f1-score 0.74), mostrando que el modelo reconoce adecuadamente ambas categor√≠as.  
- El macro promedio (0.78) confirma que el rendimiento es equilibrado entre clases.  
- Naive Bayes ofrece una soluci√≥n simple y efectiva como baseline, con bajo costo computacional y resultados competitivos.  

## üöÄ Pr√≥ximos pasos  
- Comparar desempe√±o con modelos basados en Transformers (BERT, RoBERTa).  
- Incorporar representaciones modernas de texto (embeddings contextuales). 

