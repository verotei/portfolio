# Clasificaci√≥n de Rese√±as con Naive Bayes  

‚ö†Ô∏è Proyecto en construcci√≥n. Pr√≥ximamente se agregar√°n comparaciones con otros modelos de NLP.  

## üìå Objetivo  
Explorar un m√©todo cl√°sico de Machine Learning (Naive Bayes) para clasificar rese√±as de productos en positivas o negativas.  

## üß© Contenido  
- Limpieza y preprocesamiento de texto  
- Representaci√≥n con Bag-of-Words / TF-IDF  
- Entrenamiento del modelo Naive Bayes  
- Evaluaci√≥n de m√©tricas (accuracy, precision, recall, f1-score)  
- Ejemplos pr√°cticos de clasificaci√≥n de nuevas rese√±as  

## üìä Resultados principales  

| Clase         | Precision | Recall | F1-score | Soporte |
|---------------|-----------|--------|----------|---------|
| Negativa (0)  | 0.77      | 0.91   | 0.83     | 25,138  |
| Positiva (1)  | 0.81      | 0.59   | 0.68     | 16,862  |
| **Accuracy**  |           |        | **0.78** | 42,000  |
| **Macro avg** | 0.79      | 0.75   | 0.76     | 42,000  |
| **Weighted avg** | 0.78   | 0.78   | 0.77     | 42,000  |

## ‚úÖ Conclusi√≥n  
- El modelo alcanz√≥ un **accuracy de 77,8%**.  
- Presenta un **alto recall en la clase negativa (0.91)**, lo que indica que identifica muy bien las rese√±as negativas.  
- Sin embargo, el **recall de la clase positiva es bajo (0.59)**, lo que significa que deja pasar varias rese√±as positivas sin detectarlas.  
- Este comportamiento est√° asociado al **desbalance de clases** en el dataset, donde predominan las rese√±as negativas.  
- Como baseline, Naive Bayes ofrece resultados s√≥lidos con bajo costo computacional.  
- Esta brecha entre clases lo convierte en un buen punto de partida para comparar con modelos m√°s avanzados como Transformers.  

## üöÄ Pr√≥ximos pasos  
- Comparar desempe√±o con modelos basados en Transformers (BERT, RoBERTa).  
- Analizar impacto del desbalance de clases.  
- Incorporar representaciones modernas de texto (embeddings contextuales).  
